{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE9010: Introduction to Data Science\n",
    "## Semester 2 2017/18\n",
    "## Xavier Bresson\n",
    "## ⚠ Student name: \n",
    "<br>\n",
    "\n",
    "\n",
    "## Laboratory test 1: Supervised regression\n",
    "Instruction: Check the box with the right answer.<br>\n",
    "\n",
    "Grading: You will receive 1 point for each of the questions you answer correctly.<br>\n",
    "$ $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# math library\n",
    "import numpy as np\n",
    "\n",
    "# visualization library\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 3d visualization\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "# computational time\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Supervised regression with one feature\n",
    "<hr>\n",
    "The data feature is $x$ and the data label/target is $y$.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data with numpy\n",
    "data = np.loadtxt('data/lab01_data1.txt', delimiter=',')\n",
    "#print(data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q1: What is the number $n$ of training data, and the dimension $d$ of each data?\n",
    "\n",
    "☐ $n$=47, $d$=47 <br>\n",
    "☐ $n$=2, $d$=47 <br>\n",
    "☐ $n$=47, $d$=2 <br>\n",
    "☐ $n$=2, $d$=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 2\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "n = data.shape[0] \n",
    "d = data.shape[1] \n",
    "print(n,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: What is the value of the predictive linear function $f_w(x)$ for $x=0.2$ with $w_0=0.2, w_1=-0.4$?\n",
    "\n",
    "☐ $f$ = 0.24<br>\n",
    "☐ $f$ = 0.06<br>\n",
    "☐ $f$ = 0.48<br>\n",
    "☐ $f$ = 0.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 2)\n",
      "[[ 1.       0.46985]\n",
      " [ 1.       0.3573 ]\n",
      " [ 1.       0.53595]\n",
      " [ 1.       0.31621]\n",
      " [ 1.       0.66994]]\n",
      "[[ 0.12]]\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# construct data matrix\n",
    "X = np.ones([n,2]) \n",
    "X[:,1:2] = data[:,0:1]\n",
    "print(X.shape)\n",
    "print(X[:5,:])\n",
    "\n",
    "# parameters vector\n",
    "w = np.array([0.2,-0.4])[:,None] \n",
    "\n",
    "# predictive function definition\n",
    "def f_pred(X,w): \n",
    "    f = X.dot(w) \n",
    "    return f \n",
    "\n",
    "# Test predicitive function \n",
    "x = np.array([1,0.2])[None,:] \n",
    "y_pred = f_pred(x,w)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: What is the value of the mean square error (MSE) regression loss function $L(w)$ for $w_0=0.2, w_1=-0.4$?\n",
    "\n",
    "☐ $L$ = 0.345<br>\n",
    "☐ $L$ = 0.165<br>\n",
    "☐ $L$ = 0.273<br>\n",
    "☐ $L$ = 0.657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57137]\n",
      " [ 0.47135]\n",
      " [ 0.52722]\n",
      " [ 0.33148]\n",
      " [ 0.7714 ]\n",
      " [ 0.42849]\n",
      " [ 0.44992]\n",
      " [ 0.28432]\n",
      " [ 0.3029 ]\n",
      " [ 0.34648]]\n",
      "[[ 0.27369978]]\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# loss function definition\n",
    "def loss_mse(y_pred,y): \n",
    "    n = len(y)\n",
    "    loss = 1/n* (y_pred - y).T.dot(y_pred - y) \n",
    "    return loss\n",
    "\n",
    "\n",
    "# Test loss function \n",
    "y = data[:,1][:,None] # label \n",
    "print(y[:10,:])\n",
    "y_pred = f_pred(X,w) # prediction\n",
    "loss = loss_mse(y_pred,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: What is the value of the gradient of the MSE regression loss function $\\frac{\\partial}{\\partial w} L(w)$ for $w_0=0.2, w_1=-0.4$?\n",
    "\n",
    "☐ $\\frac{\\partial}{\\partial w} L$ = [-0.43,0.49]<br>\n",
    "☐ $\\frac{\\partial}{\\partial w} L$ = [-0.93,-0.49]<br>\n",
    "☐ $\\frac{\\partial}{\\partial w} L$ = [-0.27,-0.21]<br>\n",
    "☐ $\\frac{\\partial}{\\partial w} L$ = [-0.61,0.87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93017149]\n",
      " [-0.49330366]]\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# gradient function definition\n",
    "def grad_loss(y_pred,y,X):\n",
    "    n = len(y)\n",
    "    grad = 2/n* X.T.dot(y_pred-y) \n",
    "    return grad\n",
    "\n",
    "\n",
    "# Test grad function \n",
    "y_pred = f_pred(X,w)\n",
    "grad = grad_loss(y_pred,y,X)\n",
    "print(grad)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: What is the value of the MSE regression loss function $L(w)$ after $200$ gradient descent iterations starting at $w_0=0.2, w_1=-0.4$ and selecting a learning rate $\\tau=0.1$?\n",
    "\n",
    "☐ $L$ = 0.013<br>\n",
    "☐ $L$ = 0.023<br>\n",
    "☐ $L$ = 0.008<br>\n",
    "☐ $L$ = 0.045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0130814250215\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# gradient descent function definition\n",
    "def grad_desc(X, y , w_init=np.array([0,0,0])[:,None] ,tau=0.01, max_iter=500):\n",
    "\n",
    "    L_iters = np.zeros([max_iter]) # record the loss values\n",
    "    w_iters = np.zeros([max_iter,2]) # record the loss values\n",
    "    w = w_init # initialization\n",
    "    for i in range(max_iter): # loop over the iterations\n",
    "        y_pred = f_pred(X,w) # linear predicition function #YOUR CODE HERE\n",
    "        grad_f = grad_loss(y_pred,y,X) # gradient of the loss #YOUR CODE HERE\n",
    "        w = w - tau* grad_f # update rule of gradient descent #YOUR CODE HERE\n",
    "        L_iters[i] = loss_mse(y_pred,y) # save the current loss value \n",
    "        w_iters[i,:] = w[0],w[1] # save the current w value \n",
    "        \n",
    "    return w, L_iters, w_iters\n",
    "\n",
    "\n",
    "# run gradient descent algorithm \n",
    "w_init = np.array([0.2,-0.4])[:,None]\n",
    "tau = 0.1\n",
    "max_iter = 200\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print(L_iters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: What is the value of the MSE regression loss function $L(w)$ computed with scikit-learn?\n",
    "\n",
    "☐ $L$ = 0.004<br>\n",
    "☐ $L$ = 0.006<br>\n",
    "☐ $L$ = 0.008<br>\n",
    "☐ $L$ = 0.013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss sklearn= [[ 0.00840311]]\n",
      "loss gradient descent= 0.0130814250215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xavier/.pyenv/versions/3.6.2/envs/venvp36/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# run linear regression with scikit-learn\n",
    "lin_reg_sklearn = LinearRegression()\n",
    "x_train = data[:,0][:,None]\n",
    "y_train = data[:,1]\n",
    "lin_reg_sklearn.fit(x_train, y_train) # learn the model parameters #YOUR CODE HERE\n",
    "\n",
    "# compute loss value\n",
    "w_sklearn = np.zeros([2,1])\n",
    "w_sklearn[0,0] = lin_reg_sklearn.intercept_\n",
    "w_sklearn[1:2,0] = lin_reg_sklearn.coef_\n",
    "loss_sklearn = loss_mse(f_pred(X,w_sklearn),y_train[:,None])\n",
    "print('loss sklearn=',loss_sklearn)\n",
    "print('loss gradient descent=',L_iters[-1]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: What is the value of the predictive linear function $f_w(x)$ for $x=0.2$ with the parameters $w_0,w_1$ computed with scikit-learn?\n",
    "\n",
    "☐ $f$ = 0.42<br>\n",
    "☐ $f$ = 0.11<br>\n",
    "☐ $f$ = 0.27<br>\n",
    "☐ $f$ = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.273970683974\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "print(w_sklearn.T.dot([1,0.2])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2: Supervised regression with two features\n",
    "<hr>\n",
    "The data features are $x_{(1)},x_{(2)}$ and the data label/target is $y$.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data with numpy\n",
    "data = np.loadtxt('data/lab01_data2.txt', delimiter=',')\n",
    "#print(data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: What is the value of the predictive linear function $f_w(x)$ for $x_{(1)}=0.2,x_{(2)}=0.6$ with $w_0=0.2, w_1=-0.4, w_2=0.1$?\n",
    "\n",
    "☐ $f$ = 0.18<br>\n",
    "☐ $f$ = 0.22<br>\n",
    "☐ $f$ = 0.35<br>\n",
    "☐ $f$ = 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 3)\n",
      "[[ 1.       0.46985  0.6    ]\n",
      " [ 1.       0.3573   0.6    ]\n",
      " [ 1.       0.53595  0.6    ]\n",
      " [ 1.       0.31621  0.4    ]\n",
      " [ 1.       0.66994  0.8    ]]\n",
      "[[ 0.18]]\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# construct data matrix\n",
    "X = np.ones([n,3]) \n",
    "X[:,1:3] = data[:,0:2]\n",
    "print(X.shape)\n",
    "print(X[:5,:])\n",
    "\n",
    "# parameters vector\n",
    "w = np.array([0.2,-0.4,0.1])[:,None] \n",
    "\n",
    "# predictive function definition\n",
    "def f_pred(X,w): \n",
    "    f = X.dot(w) \n",
    "    return f \n",
    "\n",
    "# Test predicitive function \n",
    "x = np.array([1,0.2,0.6])[None,:] \n",
    "y_pred = f_pred(x,w)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: What is the value of the MSE regression loss function $L(w)$ after $200$ gradient descent iterations starting at $w_0=0.2, w_1=-0.4, w_2=0.1$ and selecting a learning rate $\\tau=0.1$?\n",
    "\n",
    "☐ $L$ = 0.023<br>\n",
    "☐ $L$ = 0.029<br>\n",
    "☐ $L$ = 0.014<br>\n",
    "☐ $L$ = 0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0141011607915\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "y = data[:,2][:,None] # label \n",
    "\n",
    "# run gradient descent algorithm \n",
    "w_init = np.array([0.2,-0.4,0.1])[:,None]\n",
    "tau = 0.1\n",
    "max_iter = 200\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print(L_iters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Supervised regression with two features and the MAE loss\n",
    "<hr>\n",
    "The data features are $x_{(1)},x_{(2)}$ and the data label/target is $y$.<br>\n",
    "\n",
    "We consider a new loss defined as\n",
    "$$\n",
    "L(w)=\\frac{1}{n} \\sum_{i=1}^n \\ \\big| \\ f_w(x_i) – y_i \\ \\big|\n",
    "$$\n",
    "It is called the mean absolute error (MAE) loss, a.k.a. L1 loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: What is the value of the MAE regression loss function $L(w)$ after $200$ gradient descent iterations starting at $w_0=0.2, w_1=-0.4, w_2=0.1$ and selecting a learning rate $\\tau=0.1$?\n",
    "\n",
    "☐ $L$ = 0.014 <br>\n",
    "☐ $L$ = 0.038<br>\n",
    "☐ $L$ = 0.051<br>\n",
    "☐ $L$ = 0.074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# loss function definition\n",
    "def loss_mae(y_pred,y): \n",
    "    n = len(y)\n",
    "    loss = 1/n* np.sum(np.abs((y_pred - y)))\n",
    "    return loss\n",
    "\n",
    "def sign(x):\n",
    "    return x/ np.abs(x)\n",
    "    \n",
    "# gradient function definition\n",
    "def grad_loss(y_pred,y,X):\n",
    "    n = len(y)\n",
    "    grad = 1/n* X.T.dot(sign(y_pred-y))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0742509960921\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# gradient descent function definition\n",
    "def grad_desc(X, y , w_init=np.array([0,0,0])[:,None] ,tau=0.01, max_iter=500):\n",
    "\n",
    "    L_iters = np.zeros([max_iter]) # record the loss values\n",
    "    w_iters = np.zeros([max_iter,2]) # record the loss values\n",
    "    w = w_init # initialization\n",
    "    for i in range(max_iter): # loop over the iterations\n",
    "        y_pred = f_pred(X,w) # linear predicition function #YOUR CODE HERE\n",
    "        grad_f = grad_loss(y_pred,y,X) # gradient of the loss #YOUR CODE HERE\n",
    "        w = w - tau* grad_f # update rule of gradient descent #YOUR CODE HERE\n",
    "        L_iters[i] = loss_mae(y_pred,y) # save the current loss value \n",
    "        w_iters[i,:] = w[0],w[1] # save the current w value \n",
    "        \n",
    "    return w, L_iters, w_iters\n",
    "\n",
    "\n",
    "# run gradient descent algorithm \n",
    "w_init = np.array([0.2,-0.4,0.1])[:,None]\n",
    "tau = 0.1\n",
    "max_iter = 200\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print(L_iters[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
